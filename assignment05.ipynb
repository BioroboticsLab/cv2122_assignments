{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 5\n",
    "This notebook covers the exercises for the next two weeks (minus the Christmas break). Please upload your solution both in Whiteboard and eduflow.\n",
    "The deadline is Monday, January 10, 11:55 am."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9 (Transfer Learning)\n",
    "\n",
    "Neural need huge amount of data to be able to perform well. Huge amount of data means huge computation power... To bypass the fact that we don't own this kind of machine, we will us the transfer leaning. By using a pretrained network (usually on ImageNet) and train it a little bit, we can avoid most of the computationnal power needed to perform our task. We will work on the ResNet network (https://arxiv.org/pdf/1512.03385.pdf) designed in 2014.\n",
    "We will retrain the last layer of the network to be able to recognize leopard and cheetah. The cheetah mini database is in the image folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data_cheetah'\n",
    "TRAIN = 'train'\n",
    "TEST = 'val'\n",
    "\n",
    "# ResNet Takes 224x224 images as input, so we resize all of them\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=4,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, TEST]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "for x in [TRAIN, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "show_databatch(inputs, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Pretrained network\n",
    "\n",
    "Now load a network pre-trained on Imagenet and classify the validation data. You can import a pretrained model directly from pytorch with models.resnet18(pretrained=True). The labels are already used in ImageNet so try to recognize the database directly using the output of the pretrained network on the validation database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Transfer learning\n",
    "\n",
    "The pre-trained network can now be further trained with our data. Replace the last layer in the network with a fully connected Layer with 3 outputs for our classes cheetah, leopard and unknown. Then train the last layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 10 (UNet)\n",
    "In this assignement we are going to program our own UNet network (https://arxiv.org/pdf/1505.04597.pdf) which is a simple but powerful one. This network is made to produce a segmentation map. This segmentation map can be a little bit smaller than the true map but keep the same spatial structure. This map however is composed of several layers, one per class. The goal for the network is to activate pixel-wisely a layer if the pixel are representing the object of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\", width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The network looks this way. The descending part is simply made out of convolution layer and pooling, easy peasy. This part of the network allow a move from the \"Where?\" information to the \"What?\" information. Then the informations are spatially dilated through a so called \"transpose convolution\" looking like a convoltuion mixed with an inverse pooling and then you convolute. As I said above, there is one layer of exit per class, don't trust the drawing too much, the initial version of this network was only design to say yes or not (That why there is two output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Image(url= \"https://miro.medium.com/max/3200/0*mk6U6zQDuoQLK7Ca\", width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After each big step of convolution, the information is stacked to the last part of the network (grey arrow) reinjecting the \"Where?\" information.\n",
    "\n",
    "### 10.1 UNet Setup\n",
    "\n",
    "You have to reproduce this network by yourself. The images taken for this work come from the PascalVOC database [http://host.robots.ox.ac.uk/pascal/VOC/](http://host.robots.ox.ac.uk/pascal/VOC/). Here you inject RGB images into your network and out a \"cube\" of maps. The label of the data are on the shape of images with one channel, the background is represented by 0 and each different class by a unique label.\n",
    "\n",
    "You have to use dtype=torch.float32 for the images and dtype=torch.long for the mask and every thing should run perfectly. Use also the criterion = nn.CrossEntropyLoss() (https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss).\n",
    "\n",
    "Try to work on this early, the training can be slow (like 1h for 50 epochs; batch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Function\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VOCSegLoader(torchvision.datasets.VOCSegmentation):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 year='2012',\n",
    "                 image_set='train',\n",
    "                 download=False,\n",
    "                 transform=None,\n",
    "                 target_transform=None,\n",
    "                 transforms=None):\n",
    "\n",
    "        super(VOCSegLoader, self).__init__(root, year, image_set, download, transform, target_transform, transforms)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is the image segmentation.\n",
    "        \"\"\"\n",
    "        img = Image.open(self.images[index]).convert('RGB')\n",
    "        target = Image.open(self.masks[index])\n",
    "\n",
    "        target = np.array(target)\n",
    "        target[target == 255] = 0\n",
    "        target = Image.fromarray(target)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        target = torch.as_tensor(np.asarray(target, dtype=np.uint8), dtype=torch.long)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_epochs = 3\n",
    "batch_size_train = 100\n",
    "batch_size_val = 100\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "log_interval = 10\n",
    "image_size = (64, 85)\n",
    "\n",
    "\n",
    "transform_data = torchvision.transforms.Compose([torchvision.transforms.Resize(image_size),\n",
    "                                                 torchvision.transforms.ToTensor()])\n",
    "transform_label = torchvision.transforms.Compose([torchvision.transforms.Resize(image_size, interpolation=0)])\n",
    "\n",
    "\n",
    "train_dataset = VOCSegLoader('./data', year='2012', image_set='train', download=True,\n",
    "                             transform=transform_data, target_transform=transform_label)\n",
    "val_dataset = VOCSegLoader('./data', year='2012', image_set='val', download=True,\n",
    "                           transform=transform_data , target_transform=transform_label)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size_train)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image, target = train_dataset[0]\n",
    "print(type(image), image.size())\n",
    "print(type(target), target.size())\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.asarray(target))\n",
    "plt.show()\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    #print(out.numpy())\n",
    "    imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 10.2 Reinjection Link Manipulation\n",
    "Once you have done that, we want you to redesign a network where you remove to reinjection link (grey arrow on the drawing). You can remove the both from your choice just try and tell us if it's still working and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Congratz, you made it through Assignment 5! You can now try to solve this optional exercise.\n",
    "\n",
    "This exercise is not graded, but might be a good preparation for the exam.\n",
    "\n",
    "Please go to the following link: [Google Form](https://forms.gle/rqmQgTYaqeamwzRV7).\n",
    "\n",
    "\n",
    "In the form, you will find the optional task (and the corresponding consent form in case you agree with us processing your data). The task is formulated in German, and we would prefer German as the language for your answer. However, if you donâ€™t feel comfortable with that, please feel free to solve it in English."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}